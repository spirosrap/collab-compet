{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"Tennis_Linux_NoVis/Tennis.x86_64\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "# size of each action\n",
    "# actions between -1 and 1\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2/3000   0% ETA:   0:03:09 |-                                       | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0000 episode 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 101/3000   3% ETA:   0:07:40 |-                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0018 episode 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 201/3000   6% ETA:   0:08:11 |/                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0100 episode 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 301/3000  10% ETA:   0:08:02 |\\                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0070 episode 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 402/3000  13% ETA:   0:08:08 |\\                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0200 episode 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 501/3000  16% ETA:   0:08:09 |-                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0290 episode 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 601/3000  20% ETA:   0:08:13 |-                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0398 episode 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 701/3000  23% ETA:   0:08:11 |-                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0487 episode 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 801/3000  26% ETA:   0:08:23 ||                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0746 episode 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 901/3000  30% ETA:   0:08:35 |/                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0755 episode 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1002/3000  33% ETA:   0:08:41 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0886 episode 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1101/3000  36% ETA:   0:09:01 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.1083 episode 1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1201/3000  40% ETA:   0:09:10 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.1121 episode 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1301/3000  43% ETA:   0:10:22 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.2465 episode 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1401/3000  46% ETA:   0:14:24 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.6683 episode 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1502/3000  50% ETA:   0:17:55 |/                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.8167 episode 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1601/3000  53% ETA:   0:20:15 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.5993 episode 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1701/3000  56% ETA:   0:22:00 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.9566 episode 1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1801/3000  60% ETA:   0:22:53 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.7954 episode 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1901/3000  63% ETA:   0:23:46 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.8608 episode 1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2001/3000  66% ETA:   0:22:32 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.5339 episode 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2101/3000  70% ETA:   0:22:24 |/                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.9288 episode 2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2201/3000  73% ETA:   0:21:37 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.9444 episode 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2301/3000  76% ETA:   0:19:37 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.7498 episode 2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2401/3000  80% ETA:   0:17:16 |/                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.6455 episode 2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2501/3000  83% ETA:   0:14:56 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.6324 episode 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2601/3000  86% ETA:   0:12:55 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.1724 episode 2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2701/3000  90% ETA:   0:10:45 |/                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.3922 episode 2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2801/3000  93% ETA:   0:07:36 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.0968 episode 2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2901/3000  96% ETA:   0:03:59 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.0856 episode 2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3000/3000 100% Time:  2:04:36 ||                                    | \n"
     ]
    }
   ],
   "source": [
    "# main function that sets up environments\n",
    "# perform training loop\n",
    "\n",
    "from buffer import ReplayBuffer\n",
    "from maddpg import MADDPG\n",
    "import torch\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "from utilities import transpose_list, transpose_to_tensor\n",
    "from collections import deque\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# for saving gif\n",
    "import imageio\n",
    "\n",
    "def seeding(seed=1):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def pre_process(entity, batchsize):\n",
    "    processed_entity = []\n",
    "    for j in range(3):\n",
    "        list = []\n",
    "        for i in range(batchsize):\n",
    "            b = entity[i][j]\n",
    "            list.append(b)\n",
    "        c = torch.Tensor(list)\n",
    "        processed_entity.append(c)\n",
    "    return processed_entity\n",
    "\n",
    "\n",
    "seeding()\n",
    "\n",
    "# number of parallel agents\n",
    "# parallel_envs = 4\n",
    "\n",
    "# number of training episodes.\n",
    "# change this to higher number to experiment. say 30000.\n",
    "number_of_episodes = 3000\n",
    "episode_length = 1000\n",
    "batchsize = 128\n",
    "# how many episodes to save policy and gif\n",
    "save_interval = 1000\n",
    "t = 0\n",
    "\n",
    "scores_deque = deque(maxlen=100)\n",
    "scores = []\n",
    "\n",
    "# amplitude of OU noise\n",
    "# this slowly decreases to 0\n",
    "noise = 2\n",
    "noise_reduction = 0.9999\n",
    "\n",
    "# how many episodes before update\n",
    "episode_per_update = 2\n",
    "\n",
    "log_path = os.getcwd()+\"/log\"\n",
    "model_dir= os.getcwd()+\"/model_dir\"\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# torch.set_num_threads(parallel_envs)\n",
    "# env = envs.make_parallel_env(parallel_envs)\n",
    "\n",
    "# keep 5000 episodes worth of replay\n",
    "buffer = ReplayBuffer(500000,batchsize,0)\n",
    "\n",
    "# initialize policy and critic\n",
    "maddpg = MADDPG(seed=100)\n",
    "logger = SummaryWriter(log_dir=log_path)\n",
    "agent0_reward = []\n",
    "agent1_reward = []\n",
    "\n",
    "# training loop\n",
    "# show progressbar\n",
    "import progressbar as pb\n",
    "widget = ['episode: ', pb.Counter(),'/',str(number_of_episodes),' ', \n",
    "          pb.Percentage(), ' ', pb.ETA(), ' ', pb.Bar(marker=pb.RotatingMarker()), ' ' ]\n",
    "\n",
    "timer = pb.ProgressBar(widgets=widget, maxval=number_of_episodes).start()\n",
    "\n",
    "best_score = 0\n",
    "max_score = 0\n",
    "\n",
    "# use keep_awake to keep workspace from disconnecting\n",
    "for episode in range(0, number_of_episodes):\n",
    "\n",
    "    timer.update(episode)\n",
    "\n",
    "    for agent in maddpg.maddpg_agent:\n",
    "        agent.noise.reset()\n",
    "\n",
    "    reward_this_episode = np.zeros(2)\n",
    "    env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "    state = env_info.vector_observations # get the current state (for each agent)\n",
    "\n",
    "    #for calculating rewards for this particular episode - addition of all time steps\n",
    "\n",
    "    # save info or not\n",
    "    save_info = ((episode % save_interval) < episode==number_of_episodes)\n",
    "    frames = []\n",
    "    tmax = 0\n",
    "\n",
    "#     if save_info:\n",
    "#         frames.append(env.render('rgb_array'))\n",
    "\n",
    "    r0 = 0\n",
    "    r1 = 0\n",
    "    for episode_t in range(episode_length):\n",
    "\n",
    "        t += 1\n",
    "\n",
    "\n",
    "        # explore = only explore for a certain number of episodes\n",
    "        # action input needs to be transposed\n",
    "        actions = maddpg.act(torch.tensor(state,dtype=torch.float).to(device), noise=noise)\n",
    "        noise *= noise_reduction\n",
    "\n",
    "        action = torch.stack(actions).detach().numpy()\n",
    "\n",
    "        # step forward one frame\n",
    "        # next_obs, next_obs_full, rewards, dones, info = env.step(actions_for_env)\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "        reward = env_info.rewards\n",
    "        done = env_info.local_done\n",
    "        \n",
    "        cat_state = np.concatenate((state[0],state[1]))\n",
    "        cat_next_state = np.concatenate((next_state[0],next_state[1]))\n",
    "        \n",
    "        # add data to buffer\n",
    "        #transition = (obs, obs_full, actions_for_env, rewards, next_obs, next_obs_full, dones)\n",
    "        transition = (state, cat_state, action, reward, next_state, cat_next_state, done)\n",
    "        \n",
    "        buffer.add(*transition)\n",
    "\n",
    "        r0 += reward[0]\n",
    "        r1 += reward[1]\n",
    "        state = next_state\n",
    "        \n",
    "        # save gif frame\n",
    "        if episode % 100 == 0 :\n",
    "#             frames.append(env.render('rgb_array'))\n",
    "            tmax+=1\n",
    "        #if any of the agents are done break   \n",
    "        if len(buffer) > batchsize and episode % episode_per_update == 0:\n",
    "            for a_i in range(2):\n",
    "                samples = buffer.sample()\n",
    "                maddpg.update(samples, a_i, logger)\n",
    "            maddpg.update_targets() #soft update the target network towards the actual networks\n",
    "        \n",
    "        if np.any(done):            \n",
    "            break            \n",
    "    # update once after every episode_per_update\n",
    "\n",
    "    agent0_reward.append(r0)\n",
    "    agent1_reward.append(r1)\n",
    "    r = max(r0,r1)\n",
    "    \n",
    "    scores.append(r)\n",
    "    scores_deque.append(r)\n",
    "    \n",
    "    if episode % 100 == 0:\n",
    "        avg_rewards = [np.mean(agent0_reward), np.mean(agent1_reward)]\n",
    "        agent0_reward = []\n",
    "        agent1_reward = []\n",
    "        for a_i, avg_rew in enumerate(avg_rewards):\n",
    "            logger.add_scalar('agent%i/mean_episode_rewards' % a_i, avg_rewards[a_i], episode)\n",
    "#             print(\"agent %d /mean_episode_rewards %2f episode %d\",a_i,avg_rewards[a_i],episode)\n",
    "        print(\"mean_episode_rewards {:.4f} episode {}\".format(np.mean(scores_deque),episode))            \n",
    "\n",
    "        #saving model\n",
    "        save_dict_list =[]\n",
    "        if best_score < np.mean(scores_deque):\n",
    "            for i in range(2):\n",
    "\n",
    "                save_dict = {'actor_params' : maddpg.maddpg_agent[i].actor.state_dict(),\n",
    "                             'actor_optim_params': maddpg.maddpg_agent[i].actor_optimizer.state_dict(),\n",
    "                             'critic_params' : maddpg.maddpg_agent[i].critic.state_dict(),\n",
    "                             'critic_optim_params' : maddpg.maddpg_agent[i].critic_optimizer.state_dict()}\n",
    "                save_dict_list.append(save_dict)\n",
    "\n",
    "                torch.save(save_dict_list, \n",
    "                           os.path.join(model_dir, 'episode-{}.pt'.format(episode)))\n",
    "\n",
    "#             # save gif files\n",
    "#             imageio.mimsave(os.path.join(model_dir, 'episode-{}.gif'.format(episode)), \n",
    "#                             frames, duration=.04)\n",
    "            best_score = np.mean(scores_deque)\n",
    "\n",
    "env.close()\n",
    "logger.close()\n",
    "timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
