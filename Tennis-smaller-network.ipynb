{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"Tennis_Linux_NoVis/Tennis.x86_64\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "# size of each action\n",
    "# actions between -1 and 1\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2/3000   0% ETA:   0:03:13 |-                                       | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0000 episode 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 99/3000   3% ETA:   0:07:33 |/                                      | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0037 episode 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 201/3000   6% ETA:   0:09:16 |-                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0310 episode 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 301/3000  10% ETA:   0:09:22 |/                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0280 episode 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 401/3000  13% ETA:   0:09:29 ||                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0460 episode 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 501/3000  16% ETA:   0:09:21 |\\                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0450 episode 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 601/3000  20% ETA:   0:09:04 |-                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0360 episode 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 701/3000  23% ETA:   0:08:53 |-                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0440 episode 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 801/3000  26% ETA:   0:08:39 |/                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0480 episode 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 901/3000  30% ETA:   0:08:32 |-                                     | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0510 episode 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1001/3000  33% ETA:   0:08:10 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0403 episode 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1101/3000  36% ETA:   0:08:07 |/                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0693 episode 1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1201/3000  40% ETA:   0:08:08 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.0979 episode 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1301/3000  43% ETA:   0:08:35 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.2097 episode 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1401/3000  46% ETA:   0:12:53 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.8383 episode 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1501/3000  50% ETA:   0:16:30 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.7591 episode 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1602/3000  53% ETA:   0:17:08 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.4301 episode 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1701/3000  56% ETA:   0:20:45 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.1486 episode 1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1801/3000  60% ETA:   0:23:30 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.1596 episode 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1902/3000  63% ETA:   0:23:15 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.7937 episode 1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2002/3000  66% ETA:   0:23:53 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.0498 episode 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2101/3000  70% ETA:   0:24:12 |/                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.0916 episode 2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2201/3000  73% ETA:   0:25:33 |/                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.6799 episode 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2301/3000  76% ETA:   0:25:17 |/                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.5299 episode 2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2401/3000  80% ETA:   0:24:27 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.7619 episode 2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2501/3000  83% ETA:   0:22:28 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.7658 episode 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2601/3000  86% ETA:   0:18:03 |\\                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.6297 episode 2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2701/3000  90% ETA:   0:14:06 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.1352 episode 2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2801/3000  93% ETA:   0:09:30 ||                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 0.7458 episode 2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2901/3000  96% ETA:   0:04:53 |-                                    | "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_rewards 1.0032 episode 2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3000/3000 100% Time:  2:28:35 ||                                    | \n"
     ]
    }
   ],
   "source": [
    "# main function that sets up environments\n",
    "# perform training loop\n",
    "\n",
    "from buffer import ReplayBuffer\n",
    "from maddpg import MADDPG\n",
    "import torch\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "from utilities import transpose_list, transpose_to_tensor\n",
    "from collections import deque\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# for saving gif\n",
    "import imageio\n",
    "\n",
    "def seeding(seed=1):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def pre_process(entity, batchsize):\n",
    "    processed_entity = []\n",
    "    for j in range(3):\n",
    "        list = []\n",
    "        for i in range(batchsize):\n",
    "            b = entity[i][j]\n",
    "            list.append(b)\n",
    "        c = torch.Tensor(list)\n",
    "        processed_entity.append(c)\n",
    "    return processed_entity\n",
    "\n",
    "\n",
    "seeding()\n",
    "\n",
    "# number of parallel agents\n",
    "# parallel_envs = 4\n",
    "\n",
    "# number of training episodes.\n",
    "# change this to higher number to experiment. say 30000.\n",
    "number_of_episodes = 3000\n",
    "episode_length = 1000\n",
    "batchsize = 128\n",
    "# how many episodes to save policy and gif\n",
    "save_interval = 1000\n",
    "t = 0\n",
    "\n",
    "scores_deque = deque(maxlen=100)\n",
    "scores = []\n",
    "\n",
    "# amplitude of OU noise\n",
    "# this slowly decreases to 0\n",
    "noise = 2\n",
    "noise_reduction = 0.9999\n",
    "\n",
    "# how many episodes before update\n",
    "episode_per_update = 2\n",
    "\n",
    "log_path = os.getcwd()+\"/log\"\n",
    "model_dir= os.getcwd()+\"/model_dir\"\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# torch.set_num_threads(parallel_envs)\n",
    "# env = envs.make_parallel_env(parallel_envs)\n",
    "\n",
    "# keep 5000 episodes worth of replay\n",
    "buffer = ReplayBuffer(500000,batchsize,0)\n",
    "\n",
    "# initialize policy and critic\n",
    "maddpg = MADDPG(seed=100)\n",
    "logger = SummaryWriter(log_dir=log_path)\n",
    "agent0_reward = []\n",
    "agent1_reward = []\n",
    "\n",
    "# training loop\n",
    "# show progressbar\n",
    "import progressbar as pb\n",
    "widget = ['episode: ', pb.Counter(),'/',str(number_of_episodes),' ', \n",
    "          pb.Percentage(), ' ', pb.ETA(), ' ', pb.Bar(marker=pb.RotatingMarker()), ' ' ]\n",
    "\n",
    "timer = pb.ProgressBar(widgets=widget, maxval=number_of_episodes).start()\n",
    "\n",
    "best_score = 0\n",
    "max_score = 0\n",
    "\n",
    "# use keep_awake to keep workspace from disconnecting\n",
    "for episode in range(0, number_of_episodes):\n",
    "\n",
    "    timer.update(episode)\n",
    "\n",
    "    for agent in maddpg.maddpg_agent:\n",
    "        agent.noise.reset()\n",
    "\n",
    "    reward_this_episode = np.zeros(2)\n",
    "    env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "    state = env_info.vector_observations # get the current state (for each agent)\n",
    "\n",
    "    #for calculating rewards for this particular episode - addition of all time steps\n",
    "\n",
    "    # save info or not\n",
    "    save_info = ((episode % save_interval) < episode==number_of_episodes)\n",
    "    frames = []\n",
    "    tmax = 0\n",
    "\n",
    "#     if save_info:\n",
    "#         frames.append(env.render('rgb_array'))\n",
    "\n",
    "    r0 = 0\n",
    "    r1 = 0\n",
    "    for episode_t in range(episode_length):\n",
    "\n",
    "        t += 1\n",
    "\n",
    "\n",
    "        # explore = only explore for a certain number of episodes\n",
    "        # action input needs to be transposed\n",
    "        actions = maddpg.act(torch.tensor(state,dtype=torch.float).to(device), noise=noise)\n",
    "        noise *= noise_reduction\n",
    "\n",
    "        action = torch.stack(actions).detach().numpy()\n",
    "\n",
    "        # step forward one frame\n",
    "        # next_obs, next_obs_full, rewards, dones, info = env.step(actions_for_env)\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "        reward = env_info.rewards\n",
    "        done = env_info.local_done\n",
    "        \n",
    "        cat_state = np.concatenate((state[0],state[1]))\n",
    "        cat_next_state = np.concatenate((next_state[0],next_state[1]))\n",
    "        \n",
    "        # add data to buffer\n",
    "        #transition = (obs, obs_full, actions_for_env, rewards, next_obs, next_obs_full, dones)\n",
    "        transition = (state, cat_state, action, reward, next_state, cat_next_state, done)\n",
    "        \n",
    "        buffer.add(*transition)\n",
    "\n",
    "        r0 += reward[0]\n",
    "        r1 += reward[1]\n",
    "        state = next_state\n",
    "        \n",
    "        # save gif frame\n",
    "        if episode % 100 == 0 :\n",
    "#             frames.append(env.render('rgb_array'))\n",
    "            tmax+=1\n",
    "        #if any of the agents are done break   \n",
    "        if len(buffer) > batchsize and episode % episode_per_update == 0:\n",
    "            for a_i in range(2):\n",
    "                samples = buffer.sample()\n",
    "                maddpg.update(samples, a_i, logger)\n",
    "            maddpg.update_targets() #soft update the target network towards the actual networks\n",
    "        \n",
    "        if np.any(done):            \n",
    "            break            \n",
    "    # update once after every episode_per_update\n",
    "\n",
    "    agent0_reward.append(r0)\n",
    "    agent1_reward.append(r1)\n",
    "    r = max(r0,r1)\n",
    "    \n",
    "    scores.append(r)\n",
    "    scores_deque.append(r)\n",
    "    \n",
    "    if episode % 100 == 0:\n",
    "        avg_rewards = [np.mean(agent0_reward), np.mean(agent1_reward)]\n",
    "        agent0_reward = []\n",
    "        agent1_reward = []\n",
    "        for a_i, avg_rew in enumerate(avg_rewards):\n",
    "            logger.add_scalar('agent%i/mean_episode_rewards' % a_i, avg_rewards[a_i], episode)\n",
    "#             print(\"agent %d /mean_episode_rewards %2f episode %d\",a_i,avg_rewards[a_i],episode)\n",
    "        print(\"mean_episode_rewards {:.4f} episode {}\".format(np.mean(scores_deque),episode))            \n",
    "\n",
    "        #saving model\n",
    "        save_dict_list =[]\n",
    "        if best_score < np.mean(scores_deque):\n",
    "            for i in range(2):\n",
    "\n",
    "                save_dict = {'actor_params' : maddpg.maddpg_agent[i].actor.state_dict(),\n",
    "                             'actor_optim_params': maddpg.maddpg_agent[i].actor_optimizer.state_dict(),\n",
    "                             'critic_params' : maddpg.maddpg_agent[i].critic.state_dict(),\n",
    "                             'critic_optim_params' : maddpg.maddpg_agent[i].critic_optimizer.state_dict()}\n",
    "                save_dict_list.append(save_dict)\n",
    "\n",
    "                torch.save(save_dict_list, \n",
    "                           os.path.join(model_dir, 'episode-{}.pt'.format(episode)))\n",
    "\n",
    "            # save gif files\n",
    "            imageio.mimsave(os.path.join(model_dir, 'episode-{}.gif'.format(episode)), \n",
    "                            frames, duration=.04)\n",
    "            best_score = np.mean(scores_deque)\n",
    "\n",
    "env.close()\n",
    "logger.close()\n",
    "timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
